# ASL to Text Interpreter 🤟

Real-time ASL interpreter using OpenCV and TensorFlow/Keras for hand gesture recognition. Features custom hand tracking, image preprocessing, and gesture classification to translate American Sign Language into text output. Built with accessibility in mind.

> ⚠️ **Note:** This project is currently under development.

## Features in Development

- Real-time hand gesture detection and tracking
- Image preprocessing pipeline
- Machine learning-based gesture classification
- Support for basic ASL gestures (only letters)

## Technical Stack

- Python 3.9+
- OpenCV (Computer Vision)
- TensorFlow/Keras (Machine Learning)
- cvzone (Hand Tracking)
- NumPy (Numerical Processing)

## Project Structure

```
asl-to-text/
│
├── Application.py 
├── dataCollection.py
├── data
├── model/             
│   ├── keras_model.h5  
│   └── labels.txt     
├── README.md
└── requirements.txt     
```

## Planned Features

- Text-to-speech functionality
- Expanded gesture vocabulary
- Improved model accuracy
- Support for continuous sentence formation
- GUI interface
- Multiple hand gesture support

## Development Status

This project is in active development. Current focus areas:
- Improving hand tracking accuracy
- Expanding the gesture recognition dataset
- Enhancing real-time performance
- Building out the core classification system

## Requirements

- Python 3.8 or higher
- Webcam or camera device
- Key packages: opencv-python, tensorflow, numpy, cvzone

---
*More documentation will be added as the project develops.*